quarkus.http.port = 8080

# PostgreSQL database automatically created by Dev Services with the following settings
quarkus.devservices.enabled = true
quarkus.datasource.devservices.port = 5432
quarkus.datasource.devservices.db-name = quarkus
quarkus.datasource.devservices.username = quarkus
quarkus.datasource.devservices.password = quarkus

quarkus.hibernate-orm.schema-management.strategy = drop-and-create
quarkus.hibernate-orm.log.sql = true

quarkus.langchain4j.log-requests = true
quarkus.langchain4j.log-responses = true
# The temperature to use for the chat model. Temperature is a value between 0 and 1, where lower values make the model more deterministic and higher values make it more creative.
quarkus.langchain4j.temperature = 0.1
# Global timeout for requests to LLM APIs
quarkus.langchain4j.timeout = 120s
quarkus.langchain4j.guardrails.max-retries = 2

# The chat model to use. In case of Ollama, llama3.1 is the default chat model.
quarkus.langchain4j.ollama.chat-model.model-id = llama3.1
# The format to return a response in. Format can be json or a JSON schema, or text; in this application, we use JSON.
quarkus.langchain4j.ollama.chat-model.format = JSON

# The REST Assured client timeout for testing.
quarkus.http.test-timeout = 60s

# LangFuse OpenTelemetry settings; set to false to disable
quarkus.otel.enabled = true
quarkus.otel.metrics.enabled = true
# OpenTelemetry defines the encoding of telemetry data and the protocol used to exchange data between the client and the server. Default is grpc.
quarkus.otel.exporter.otlp.traces.protocol = http/protobuf
# LangFuse OpenTelemetry endpoint and authorization header
quarkus.otel.exporter.otlp.traces.headers = Authorization=Basic ***
quarkus.otel.exporter.otlp.traces.endpoint = http://localhost:3000/api/public/otel
quarkus.langchain4j.tracing.include-prompt = true
quarkus.langchain4j.tracing.include-completion = true
quarkus.langchain4j.tracing.include-tool-arguments=true
quarkus.langchain4j.tracing.include-tool-result=true

# Grafana and OpenTelemetry ports for LGTM observability; by default testcontainers exposes these on random ports.
quarkus.observability.lgtm.grafana-port = 3001
quarkus.observability.lgtm.otel-grpc-port = 5317
quarkus.observability.lgtm.otel-http-port = 5318
# Grafana LGTM metrics
quarkus.otel.exporter.otlp.metrics.endpoint = http://localhost:5318
quarkus.otel.exporter.otlp.metrics.protocol = http/protobuf
#Grafana LGTM logs
quarkus.otel.exporter.otlp.logs.endpoint = http://localhost:5318
quarkus.otel.exporter.otlp.logs.protocol = http/protobuf
