quarkus.http.port = 8080

# PostgreSQL database automatically created by Dev Services with the following settings
quarkus.devservices.enabled = true
quarkus.datasource.devservices.port = 5432
quarkus.datasource.devservices.db-name = quarkus
quarkus.datasource.devservices.username = quarkus
quarkus.datasource.devservices.password = quarkus

quarkus.hibernate-orm.schema-management.strategy = drop-and-create
quarkus.hibernate-orm.log.sql = true

quarkus.langchain4j.log-requests = true
quarkus.langchain4j.log-responses = true
# The temperature to use for the chat model. Temperature is a value between 0 and 1, where lower values make the model more deterministic and higher values make it more creative.
quarkus.langchain4j.temperature = 0.05
# Global timeout for requests to LLM APIs
quarkus.langchain4j.timeout = 90s

# The chat model to use. In case of Ollama, llama3.1 is the default chat model.
quarkus.langchain4j.ollama.chat-model.model-id = llama3.1
# The format to return a response in. Format can be json or a JSON schema, or text; in this application, we use text.
quarkus.langchain4j.ollama.chat-model.format = JSON

# The REST Assured client timeout for testing.
quarkus.http.test-timeout = 60s
